experiment_name: hpx64_coupled-dlwp-olr_seed0
output_dir: outputs/${experiment_name}
checkpoint_name: null
load_weights_only: false
seed: 0
batch_size: 14
learning_rate: 0.0002
num_workers: 1
port: 29465
master_address: localhost
data:
  module:
    _target_: training.dlwp.data.modules.CoupledTimeSeriesDataModule
    src_directory: ${data.src_directory}
    dst_directory: ${data.dst_directory}
    dataset_name: ${data.dataset_name}
    prefix: ${data.prefix}
    suffix: ${data.suffix}
    data_format: ${data.data_format}
    batch_size: ${batch_size}
    drop_last: true
    input_variables: ${data.input_variables}
    output_variables: ${data.output_variables}
    constants: ${data.constants}
    scaling: ${data.scaling}
    splits: ${data.splits}
    presteps: ${model.presteps}
    input_time_dim: ${data.input_time_dim}
    output_time_dim: ${data.output_time_dim}
    data_time_step: ${data.data_time_step}
    time_step: ${data.time_step}
    gap: ${data.gap}
    shuffle: true
    add_insolation: ${data.add_insolation}
    cube_dim: ${data.cube_dim}
    num_workers: ${num_workers}
    pin_memory: true
    prebuilt_dataset: ${data.prebuilt_dataset}
    couplings:
    - coupler: ConstantCoupler
      params:
        batch_size: ${batch_size}
        variables:
        - sst
        input_times:
        - 0H
        input_time_dim: ${data.input_time_dim}
        output_time_dim: ${data.output_time_dim}
        presteps: ${model.presteps}
        prepared_coupled_data: true
  scaling:
    ws10-48H:
      mean: 6.153011322021484
      std: 3.20932674407959
    z1000-48H:
      mean: 936.2125244140625
      std: 859.9105224609375
    olr-48H:
      mean: 319.0035705566406
      std: 76.94828796386719
    sst:
      mean: 290.95892333984375
      std: 10.623672485351562
    ws10:
      mean: 6.1527934074401855
      std: 3.650933265686035
    z1000:
      mean: 936.1904907226562
      std: 903.8828125
    t2m0:
      mean: 287.5758361816406
      std: 15.393858909606934
    t850:
      mean: 280.5975036621094
      std: 12.360532760620117
    z500:
      mean: 55482.71875
      std: 2740.59130859375
    tau300-700:
      mean: 61743.29296875
      std: 2610.57080078125
    tcwv0:
      mean: 24.324907302856445
      std: 16.810949325561523
    z250:
      mean: 103530.8125
      std: 4612.06005859375
    olr:
      mean: 319.032470703125
      std: 91.53726959228516
  splits:
    train_date_start: '1983-07-02'
    train_date_end: 2016-06-30T22:00
    val_date_start: '2016-07-01'
    val_date_end: 2017-06-30T22:00
    test_date_start: '2016-07-01'
    test_date_end: 2017-06-30T22:00
  src_directory: /home/mercury2/nacc/data/HPX64
  dst_directory: /home/mercury2/nacc/data/HPX64
  dataset_name: hpx64_1983-2017_3h_9varCoupledAtmos-sst
  prefix: era5_1deg_3h_HPX32_1979-2021_
  suffix: ''
  data_format: classic
  input_variables:
  - z500
  - tau300-700
  - z1000
  - t2m0
  - tcwv0
  - t850
  - z250
  - ws10
  - olr
  output_variables: null
  constants:
    land_sea_mask: lsm
    topography: z
  input_time_dim: 2
  output_time_dim: 4
  data_time_step: 3H
  time_step: 6H
  gap: 6H
  add_insolation: true
  nside: 64
  cube_dim: ${data.nside}
  prebuilt_dataset: true
model:
  encoder:
    conv_block:
      activation:
        _target_: training.dlwp.model.modules.activations.CappedGELU
        cap_value: 10
      _target_: training.dlwp.model.modules.blocks.SymmetricConvNeXtBlock
      _recursive_: true
      in_channels: 3
      out_channels: 1
      kernel_size: 3
      dilation: 1
      upscale_factor: 4
    down_sampling_block:
      _target_: training.dlwp.model.modules.blocks.AvgPool
      pooling: 2
    recurrent_block:
      _target_: training.dlwp.model.modules.blocks.ConvGRUBlock
      _recursive_: false
      in_channels: 3
      kernel_size: 1
      downscale_factor: 4
    _target_: training.dlwp.model.modules.encoder.UNetEncoder
    _recursive_: false
    n_channels:
    - 180
    - 90
    - 90
    dilations:
    - 1
    - 2
    - 4
  decoder:
    conv_block:
      activation:
        _target_: training.dlwp.model.modules.activations.CappedGELU
        cap_value: 10
      _target_: training.dlwp.model.modules.blocks.SymmetricConvNeXtBlock
      _recursive_: true
      in_channels: 3
      out_channels: 1
      kernel_size: 3
      dilation: 1
      upscale_factor: 4
    up_sampling_block:
      activation:
        _target_: training.dlwp.model.modules.activations.CappedGELU
        cap_value: 10
      _target_: training.dlwp.model.modules.blocks.TransposedConvUpsample
      in_channels: 3
      out_channels: 1
      upsampling: 2
    recurrent_block:
      _target_: training.dlwp.model.modules.blocks.ConvGRUBlock
      _recursive_: false
      in_channels: 3
      kernel_size: 1
      downscale_factor: 4
    output_layer:
      _target_: training.dlwp.model.modules.blocks.BasicConvBlock
      in_channels: 3
      out_channels: 2
      kernel_size: 1
      dilation: 1
      n_layers: 1
    _target_: training.dlwp.model.modules.decoder.UNetDecoder
    _recursive_: false
    n_channels:
    - 90
    - 90
    - 180
    dilations:
    - 4
    - 2
    - 1
  _target_: training.dlwp.model.models.unet.HEALPixRecUNet
  _recursive_: false
  presteps: 1
  input_time_dim: ${data.input_time_dim}
  output_time_dim: ${data.output_time_dim}
  delta_time: ${data.time_step}
  couplings: ${..data.module.couplings}
  input_channels: 7
  output_channels: 7
  n_constants: 2
  decoder_input_channels: 1
  enable_nhwc: false
  enable_healpixpad: true
trainer:
  criterion:
    _target_: training.dlwp.trainer.criterion.WeightedMSE
    weights:
    - 1.5054
    - 0.875
    - 0.2817
    - 0.4683
    - 0.1034
    - 0.2619
    - 2.9634
    - 0.0231
    - 0.0055
  optimizer:
    _target_: torch.optim.Adam
    lr: ${learning_rate}
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    optimizer: ${model.optimizer}
    T_max: ${trainer.max_epochs}
    eta_min: 4.0e-05
    last_epoch: -1
    verbose: false
  _target_: training.dlwp.trainer.trainer.Trainer
  _recursive_: true
  max_epochs: 250
  min_epochs: 1
  early_stopping_patience: null
  amp_mode: fp16
  graph_mode: train_eval
  output_dir: ${output_dir}
  keep_n_checkpoints: 16
  max_norm: 0.25
